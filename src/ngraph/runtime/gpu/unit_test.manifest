# need to check
computation_reuse
# int64 is not supprted by cuDNN
dot_matrix_vector_int64
generate_mask
# custom_mem is not implemented on GPU
tensorview_custom_mem
# integer is not supported by cuDNN on backward pooling
backwards_maxpool_n4_c1_hw4_2x2_max
backwards_maxpool_n2_c1_hw5_3x3_str2_max
backwards_avgpool_n1_c1_hw2x2
backwards_avgpool_n1_c1_hw4x4
backwards_avgpool_n2_c2_hw4x4
embedding_lookup_4x5_reverse
embedding_lookup_10x1_arbitrary
embedding_lookup_10x1_arbitrary_index_type_int
embedding_lookup_10x1_arbitrary_index_type_int64
batch_norm_inference_0eps_f64
batch_norm_inference_0eps_f32
batch_norm_inference_f64
batch_norm_inference_f32
batch_norm_training_0eps_f64
batch_norm_training_0eps_f32
backwards_batch_norm_training
dequantize
dequantize_zero_offset
dequantize_axes
dequantize_dynamic_offset
dequantize_int8
dequantize_int8_zero_offset
dequantize_int32
dequantize_int32_zero_offset
quantize
quantize_zero_offset
quantize_axes
quantize_dynamic_offset
quantize_int8
quantize_int8_zero_offset
quantize_int32
quantize_int32_zero_offset
quantize_clamp_uint8
quantize_clamp_int8
quantize_clamp_int32
quantize_ROUND_NEAREST_TOWARD_ZERO
quantize_ROUND_NEAREST_TOWARD_INFINITY
quantize_ROUND_NEAREST_UPWARD
quantize_ROUND_NEAREST_DOWNWARD
quantize_ROUND_NEAREST_TOWARD_EVEN
quantize_ROUND_TOWARD_INFINITY
quantize_ROUND_TOWARD_ZERO
quantize_ROUND_UP
quantize_ROUND_DOWN
shape_of_scalar
shape_of_vector
shape_of_matrix
shape_of_5d
# zero size axis needs to be implemented
# differently in gpu_emitter.cpp
# these should be re-enabled before
# merging to master
product_matrix_rows_zero
product_matrix_cols_zero
product_vector_zero
product_matrix_to_scalar_zero_by_zero
product_3d_eliminate_zero_dim
max_matrix_rows_zero_int32
any_trivial
any_2x2_to_scalar_true
any_2x2_to_scalar_false
any_2x0_to_scalar
any_2x3_eliminate_col_dim
any_2x3_eliminate_row_dim
any_2x2x3_eliminate_dim_0
any_2x2x3_eliminate_dim_1
any_2x2x3_eliminate_dim_2
any_2x2x3_eliminate_dims_0_1
any_2x2x3_eliminate_dims_0_2
any_2x2x3_eliminate_dims_1_2
any_2x2x3_eliminate_dims_0_1_2
all_trivial
all_2x2_to_scalar_false
all_2x2_to_scalar_true
all_2x0_to_scalar
all_2x3_eliminate_col_dim
all_2x3_eliminate_row_dim
all_2x2x3_eliminate_dim_0
all_2x2x3_eliminate_dim_1
all_2x2x3_eliminate_dim_2
all_2x2x3_eliminate_dims_0_1
all_2x2x3_eliminate_dims_0_2
all_2x2x3_eliminate_dims_1_2
all_2x2x3_eliminate_dims_0_1_2

# GPU backend uses floats to implement these ops for int32
floor_int32
divide_int32
one_hot_scalar_oob_in_3

# Unsupported extra pading modes
pad_edge_1d
pad_edge_1d_top_neg
pad_edge_1d_top_neg_bigger_than_tensor
pad_edge_1d_bottom_neg
pad_edge_1d_bottom_neg_bigger_than_tensor
pad_edge_2d
pad_edge_2d_with_neg
pad_reflect_1d
pad_reflect_1d_top_neg
pad_reflect_1d_top_neg_bigger_than_tensor
pad_reflect_1d_bottom_neg
pad_reflect_1d_bottom_neg_bigger_than_tensor
pad_reflect_1d_multi_reflect
pad_reflect_2d
pad_reflect_2d_with_neg

# Quantized operators are not supported on gpu backend
model_dequantize_linear
model_dequantize_linear_scalar_zero_scale_uint8
model_dequantize_linear_scalar_zero_scale_int8
model_dequantize_linear_1d_zero_scale_uint8
model_dequantize_linear_1d_zero_scale_int8
model_dequantize_linear_1d_zero_scale_int8_4d
model_dequantize_linear_1d_zero_scale_uint8_negative_axis
model_quantize_linear
model_quantize_linear_zero_point
model_quantize_linear_axis_zero
model_quantize_linear_axis_negative
model_quant_conv_linear
model_quant_conv_linear_2d
model_quant_conv_linear_3d
model_qlinear_matmul
model_qlinear_matmul_3d

# This should be implemented
create_tensor_2_input
create_tensor_2_output

# Not implemented
batch_mat_mul_forward
backwards_batchmatmul_tensor2_tensor2
erf
zero_sized_erf
model_erf
model_erf_int32
gather_no_axis
gather
gather_nd_scalar_from_2d
gather_nd_1d_from_2d
gather_nd_scalar_from_3d
gather_nd_1d_from_3d
gather_nd_2d_from_3d
gather_nd_batch_scalar_from_2d
gather_nd_batch_1d_from_2d
gather_nd_batch_scalar_from_3d
gather_nd_batch_1d_from_3d
gather_nd_batch_2d_from_3d
gather_scalar_indices_no_axis
gather_scalar_indices
gather_nd_single_indices
gemm
gemm_broadcast_input_C
model_hardmax
mvn_mean_normalization
mvn_mean_normalization_split_channels
mvn_mean_variance_normalization
mvn_mean_variance_normalization_split_channels
scatter_add_4d_indices
scatter_add_3d_indices
scatter_add_2d_indices
scatter_add_1d_indices
scatter_add_scalar_indices
scatter_nd_add_batch_2d_to_3d
scatter_nd_add_2d_to_3d
gather_no_axis_int8
gather_no_axis_int16
gather_no_axis_int32
gather_no_axis_int64
gather_no_axis_uint8
gather_no_axis_uint16
gather_no_axis_uint32
gather_no_axis_uint64
gather_no_axis_bool
fake_quantize
fake_quantize_with_clip
fake_quantize_with_clip_across_channels
